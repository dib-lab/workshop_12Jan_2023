{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53b6fa24-5411-4e2f-b4fe-ff60af12df68",
   "metadata": {},
   "source": [
    "# Downstream analysis\n",
    "We create a vcf file containing small and structral variants annotated with their AF and predicted functional impact. Here we are going to go through how to explore those variants.\n",
    "\n",
    "Let's start by visualizing structral variants to make sure that the callers did a good job.\n",
    "\n",
    "\n",
    "I am going to\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f83c765-7185-4de4-8b5f-0a0cbc148c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "grep \"cuteSV-25-8240662-DEL-0-1405\" results/cuteSV/ERR5043144.hifi.pbmm2.phased.vcf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c93ae5-5275-419b-a29c-3f33fcbc7a7b",
   "metadata": {},
   "source": [
    "# Samplot\n",
    "The variant of length(1405) starts at 8240662 and ends at 8242067. We are going to use samplot to visualize this variant. \n",
    "Plotting using our snakemake workflow is very simple. \n",
    "\n",
    "just run 'snakemake -j1 -p results/samplot/{sv\\_type}\\_{chrom}\\_{start}\\_{end}.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdb20bb-f71e-4bd9-b6d0-b4e4e7dde42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "snakemake -j1 -p results/samplot/DEL_25_8240662_8242067.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed13747c-a26f-4c86-a2fc-a4c75b12c989",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='results/samplot/DEL_25_8240662_8242067.png') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28ddb5f-3165-4f2b-870e-4dc36979d116",
   "metadata": {},
   "source": [
    "# Visualize SV Benchmark\n",
    "Benchmarking SV is not an easy job because tools always disagree about the positions of breakpoints. Therefore, we can expect that some SV in our benchmarks tagged as FP while it was correct but the breakpoint wasnt matching.\n",
    "\n",
    "Let's view a SV called by pbsv but was tagged as FP.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b597ac93-cdde-4237-be6d-92c2f4cd3780",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "grep \"pbsv-25-9733349-DEL-0-663\" results/pbsv/ERR5043144.hifi.pbmm2.phased.vcf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a75b02-3f80-4ce0-b43a-2e28fff1dc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "snakemake -j1 -p results/samplot/DEL_25_9733349_9734012.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d6a258-b9bc-41f5-bdc7-1149fefc43cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='results/samplot/DEL_25_9733349_9734012.png') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957ffafe-bba3-47a9-92af-edad0c36c0bf",
   "metadata": {},
   "source": [
    "Looks like that SV is actually correct. Lesson here is that You have to visualize SV to make sure that everything is correct."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916788e3-4191-402b-ba7d-186b4f8a1e36",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Variant Effect predictor\n",
    "We are going to use VEP to predict the effect of the variants. The following figgure summarizes the annotations produced by VEP. More information is available on their [website](https://uswest.ensembl.org/info/genome/variation/prediction/predicted_data.html)\n",
    "![VEP](https://uswest.ensembl.org/info/genome/variation/prediction/consequences.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9933bca1-ce00-4a0b-8afa-e7921405435d",
   "metadata": {},
   "source": [
    "### Run VEP using snakemake\n",
    "to get the output file for vep: replace the extnesion(\".vcf.gz\") of any compressed vcf file  with \".vep.vcf.gz\".\n",
    "\n",
    "for example: \n",
    "\n",
    "results/cuteSV/ERR7091271.ont.minimap2.phased.vcf.gz \n",
    "\n",
    "                will be\n",
    "\n",
    "results/cuteSV/ERR7091271.ont.minimap2.phased.vep.vcf.gz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e041bc5b-0298-4022-8905-9cd3769399ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "snakemake -j4 --use-conda \"results/cuteSV/ERR7091271.ont.minimap2.phased.vep.vcf.gz\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c43aca0-aea7-4898-a916-a1e75c5c7267",
   "metadata": {},
   "source": [
    "### View VEP report\n",
    "Lets first, look at the summary results they produced. \n",
    "\n",
    "1. Browse the folders using the panel on the left to \"results/cuteSV/\"\n",
    "\n",
    "2. Download the report \"ERR7091271.ont.minimap2.phased.vep.html\": right click on the file then click downloand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0ccf73-1225-4a69-8c53-0a3a0cc2f653",
   "metadata": {},
   "source": [
    "### Let's visualize a high impact variant\n",
    "We need first to get the coordinates of a high impact variant to visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd010283-920b-4f11-9d9f-3a52a1b368c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "zgrep \"coding_sequence_variant\"  results/cuteSV/ERR7091271.ont.minimap2.phased.vep.vcf.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa08ae4e-37b5-4667-ada5-203bff832e61",
   "metadata": {},
   "source": [
    "Let's visualize the first deletion(396bp) starting from 2585287 to 2585683 on chromsome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d56300-1c69-46b0-9cca-8a811671beb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "snakemake -j1 -p results/samplot/DEL_25_2585287_2585683.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b6c841-ffc9-4c86-9681-a01227320db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='results/samplot/DEL_25_2585287_2585683.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c74a6a-4d4d-4e2e-bd83-598d789bbabd",
   "metadata": {},
   "source": [
    "## Population Frequency analysis\n",
    "We calculated the AF for our VCFs in 10 samples. Here, I am providing a vcf file produced using the sample workflow but I ran the population genotyper against 428 samples. you will find the result file \"final.vep.vcf.bgz\" contianing all the vairants and \"final.SV.vep.vcf.bgz\" containing only the SV. The following table describes the metadata tagged for each variant.\n",
    "\n",
    "\n",
    "| Metadata      | Description |\n",
    "| -- |:-----------:|\n",
    "| AC | Allele count in genotypes|\n",
    "| AC_Het | Allele counts in homozygous genotypes|\n",
    "| AC_Hom | Allele counts in heterozygous genotypes|\n",
    "| AC_Hemi | Allele counts in hemizygous genotypes|\n",
    "| AF | Allele frequency |\n",
    "| MAF | Minor Allele frequency |\n",
    "| NS | Number of samples with data   |\n",
    "| AN | Total number of alleles in called genotypes |\n",
    "| HWE | Hardy-Weinberg equilibrium |\n",
    "| ExcHet | Test excess heterozygosity; 1=good, 0=bad |\n",
    "\n",
    "\n",
    "Let's first check a file called \"samples.csv\" containing breed information of the 428 animal. The following command print the first 10 animals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ad2641-cbb2-4860-aeb7-e07e754e8e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat samples.csv |head|tr -s ',' $'\\t' | ../tools/prettytable 3 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e0590f-5d81-454b-b51d-8c2a60010edb",
   "metadata": {},
   "source": [
    "The commands below count the number of samples per breed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d37bfa-ae58-4c91-8801-7b76658c9c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cut -f2 -d, samples.csv |sort |uniq -c| awk '{print $2\"\\t\"$1}' |sort -k2,2nr > tmp\n",
    "cat <(echo -e \"Breed\\tcount\") tmp | ../tools/prettytable 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a80a2d-856e-454f-86be-ef60e37d4bb5",
   "metadata": {},
   "source": [
    "### Find Rare variants\n",
    "\n",
    "Bcftools is very helpful in filtering vcf files using the variants metadata. For example, We can query the novel varaints using the following command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a3eaea-324b-4c9f-82c0-364df4de7cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "bcftools view  -Q 0.001 final.SV.vep.vcf.bgz  | grep -vP \"^#\"  |head -n 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02ca216-26df-4d6e-96b2-71dd941c08ac",
   "metadata": {},
   "source": [
    "### Finding common variants\n",
    "on the other hand we can select the most common variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abdaa7b-bec7-4b4d-a8b3-7af4a8b2a98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "bcftools view  -q 0.9 final.SV.vep.vcf.bgz  | grep -vP \"^#\"  |head -n 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11dea8fd-6f1e-440e-b65e-05c7a8a0d34e",
   "metadata": {},
   "source": [
    "# Hail\n",
    "Although bcftools is very helpful and fast but it is hard to do complex tasks with it. Here we are suggesting using Hail to be able explore the population genotyping results and get meaningful results. Hail is a python library for genomic data expoloration. It creates a matrix table for vcf files which is very similar to R dataframes.\n",
    "\n",
    "So let's do some coding by intializing Hail engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0634abc7-4b4f-433b-abce-d354727584c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hail as hl\n",
    "hl.init()\n",
    "from hail.plot import show\n",
    "from pprint import pprint\n",
    "hl.plot.output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f45585-3017-4d17-b3fb-e550c878c3f6",
   "metadata": {},
   "source": [
    "Now we are going to load the vcf and samples information to create Hail Matrix table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb96476a-782c-4f55-bea7-d5ed0c7364bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref=\"your_path_to_the_data/ARS-UCD1.2_Btau5.0.1Y.25.fa\"\n",
    "index=\"your_path_to_the_data/ARS-UCD1.2_Btau5.0.1Y.25.fa.fai\"\n",
    "vcf=\"final.SV.vep.vcf.bgz\"\n",
    "samplesInfo=\"samples.csv\"\n",
    "hlRef=hl.ReferenceGenome.from_fasta_file(\"ARSUCD\",ref,index)\n",
    "\n",
    "mt = hl.import_vcf(vcf,reference_genome=hlRef)\n",
    "table = (hl.import_table('samples.csv', impute=True,delimiter=\",\")\n",
    "         .key_by('BioSample'))\n",
    "mt = mt.annotate_cols(breed = table[mt.s])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821f1090-c61b-4b52-a7f3-537c4dc4014a",
   "metadata": {},
   "source": [
    "Lets see how the hail matrix table is organized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d27461f-4b01-461d-b543-72c8f5df69a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt.rows().show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2657f025-5c38-40f8-85b2-a8bec8aaea6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt.GT.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bcca26-23e1-44ed-83c2-cdd10a564749",
   "metadata": {},
   "outputs": [],
   "source": [
    "samplesPercohort=mt.aggregate_cols(hl.agg.counter(mt.breed.Cohort))\n",
    "print(samplesPercohort)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720f3c92-403b-433d-9f5d-67b328ab3e11",
   "metadata": {},
   "source": [
    "### Stratify population allele frequency\n",
    "Here we are trying to answer questions like which variants are frequent in the Indicus breeds only. We are going to calculate allele frequencies per cohort.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44441f9-e8fe-44ab-8b63-05c42ed8c711",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt=mt.annotate_rows(AF_indicus=hl.agg.filter(mt.breed.Cohort ==\"indicus\",\n",
    "                                     hl.agg.sum(mt.GT.n_alt_alleles())\n",
    "                                     / samplesPercohort[\"indicus\"]*2 ))\n",
    "mt=mt.annotate_rows(AF_taurus=hl.agg.filter(mt.breed.Cohort ==\"taurus\",\n",
    "                                     hl.agg.sum(mt.GT.n_alt_alleles())\n",
    "                                     / samplesPercohort[\"taurus\"]*2 ))\n",
    "mt=mt.annotate_rows(AF_bosoutgroup=hl.agg.filter(mt.breed.Cohort ==\"bosoutgroup\",\n",
    "                                     hl.agg.sum(mt.GT.n_alt_alleles())\n",
    "                                     / samplesPercohort[\"bosoutgroup\"]*2 ))\n",
    "mt.rows().show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6858967c-7d14-4700-8b74-a9aa4ef70bb8",
   "metadata": {},
   "source": [
    "Now we calculated startified AF per cohort lets find the frequent variants in Indicus samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d109ae3-5626-48d3-a14e-90bb9038d354",
   "metadata": {},
   "outputs": [],
   "source": [
    "indicusFrequent=mt.filter_rows(mt.AF_indicus > 0.7)\n",
    "indicusFrequent.rows().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa20deab-4068-46f8-bd6d-a30fa2b890d7",
   "metadata": {},
   "source": [
    "We can easily get the ids of the common variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bbd18b-9a52-4ae5-8c24-34814fa80364",
   "metadata": {},
   "outputs": [],
   "source": [
    "indicusFrequent.rows().rsid.collect()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a4dd10-cc75-492b-9126-6da1ffd0658e",
   "metadata": {},
   "source": [
    "Similarily we find common variants for the Holstein breed only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d010fbd1-1fa1-4f92-a0a0-519aaeca3055",
   "metadata": {},
   "outputs": [],
   "source": [
    "numSamples=mt.aggregate_cols(hl.agg.filter(mt.breed.CompositeBreed == \"Holstein\" ,hl.agg.count()))\n",
    "mt=mt.annotate_rows(AF_Holstein=hl.agg.filter(mt.breed.CompositeBreed ==\"Holstein\",\n",
    "                                     hl.agg.sum(mt.GT.n_alt_alleles())\n",
    "                                     / numSamples*2 ))\n",
    "\n",
    "mt.filter_rows(mt.AF_Holstein > 0.8).rows().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd266a8d-4a02-4fb0-9db2-413381d0f75f",
   "metadata": {},
   "source": [
    "## Explore population genotypes of a specfic variant\n",
    "\n",
    "Let's explore the population data of the high impact variant that we visualized earlier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df69ff9f-0f9b-4401-ad0c-0d6a6b58f999",
   "metadata": {},
   "outputs": [],
   "source": [
    "HighImpactSV=mt.filter_rows(mt.rsid==\"cuteSV-25-2585287-DEL-0-396\")\n",
    "HighImpactSV.rows().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa4cd92-2b37-491b-8cb3-763c452a6009",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Indicus Freq =%.2f\"%       HighImpactSV.rows().AF_indicus.collect()[0])\n",
    "print(\"Taurus Freq =%.2f\"%        HighImpactSV.rows().AF_taurus.collect()[0])\n",
    "print(\"Bos out group Freq =%.2f\"% HighImpactSV.rows().AF_bosoutgroup.collect()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3816ff-bdc6-49f1-9ac3-fd7a7e00f70f",
   "metadata": {},
   "source": [
    "### Here we are showing the sum of alleles found per each breed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de201625-b8f8-40fc-906c-b6bbebaad7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = HighImpactSV.entries()\n",
    "results = (entries.group_by(breed = entries.breed.CompositeBreed)\n",
    "      .aggregate(alleleCount = hl.agg.sum(entries.GT.n_alt_alleles())))\n",
    "results=results.order_by(-results.alleleCount)\n",
    "results.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd6113d-e0d8-4d1e-883d-d325d612f1d0",
   "metadata": {},
   "source": [
    "Finally get the ids of the samples that have this variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2de6251-cb32-4ff5-b238-fff2a85f0787",
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = HighImpactSV.entries()\n",
    "results = entries.filter(entries.GT.is_non_ref())\n",
    "print(results.s.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6244dc9-b27b-4939-99b4-ca2f998ffe8e",
   "metadata": {},
   "source": [
    "# Run principal component analysis (PCA) on the Hardy-Weinberg-normalized genotype call matrix.\n",
    "Finally lets run pca on the genotypes and visualize how the samples are related to each others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37af96cf-b623-486e-96f8-ca0128bfe09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvalues, pcs, _ = hl.hwe_normalized_pca(mt.GT)\n",
    "mt = mt.annotate_cols(scores = pcs[mt.s].scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7a5750-e021-4d12-a015-2c952727f093",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.models import  CategoricalColorMapper\n",
    "from bokeh.palettes import Category10\n",
    "\n",
    "pallete=Category10[3]\n",
    "colors={\n",
    "    'taurus': pallete[0],\n",
    "    'indicus': pallete[1],\n",
    "    'bosoutgroup': pallete[2]\n",
    "    \n",
    "}\n",
    "\n",
    "colorTable={}\n",
    "for s in table.collect():\n",
    "    colorTable[s.CompositeBreed]=colors[s.Cohort]\n",
    "factors=[]\n",
    "pallete=[]\n",
    "for k,v in colorTable.items():\n",
    "    factors.append(k)\n",
    "    pallete.append(v)\n",
    "    \n",
    "color_mapper = CategoricalColorMapper(factors=factors, palette=pallete)    \n",
    "\n",
    "p = hl.plot.scatter(mt.scores[0],\n",
    "                    mt.scores[1],\n",
    "                    label=mt.breed.CompositeBreed,\n",
    "                    colors=color_mapper,\n",
    "                    title='PCA', xlabel='PC1', ylabel='PC2')\n",
    "show(p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
